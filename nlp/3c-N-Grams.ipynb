{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Analysis of Alexithymic Discourse\n",
    "\n",
    "<hr>\n",
    "\n",
    "Alexithymic Language Project / raul@psicobotica.com / V2 release (sept 2020)\n",
    "\n",
    "<hr>\n",
    "\n",
    "### N-GRAMs Models\n",
    "\n",
    "An N-Gram is \"A contiguous sequence of N items from a given sample of text or speech\".\n",
    "\n",
    "- Char N-Grams.\n",
    "- Word N-Grams.\n",
    "- Language generation with N-Gram models. \n",
    "\n",
    "<hr>\n",
    "\n",
    "[Explanation of N-Gram models](https://en.wikipedia.org/wiki/N-gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features dataset\n",
    "- Data is already pre-processed (1-Preprocessing). \n",
    "- Basic NLP features are already calculated (2-Features). \n",
    "- Some additional BoW features have been added (3-BoW).\n",
    "- Some additional TF/IDF features have been added (3-TFIDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "import heapq\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dataset_path = \"https://raw.githubusercontent.com/raul-arrabales/alexithymic-lang/master/data/Prolexitim_v2_features_3.csv\"\n",
    "alex_df = pd.read_csv(feats_dataset_path, header=0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Code', 'TAS20', 'F1', 'F2', 'F3', 'Gender', 'Age', 'Card',\n",
       "       'T_Metaphors', 'T_ToM', 'T_FP', 'T_Interpret', 'T_Desc', 'T_Confussion',\n",
       "       'Text', 'Alex_A', 'Alex_B', 'Words', 'Sentences', 'Tokens',\n",
       "       'Tokens_Stop', 'Tokens_Stem_P', 'Tokens_Stem_S', 'POS', 'NER', 'DEP',\n",
       "       'Lemmas_CNLP', 'Lemmas_Spacy', 'Chars', 'avgWL', 'avgSL', 'Pun_Count',\n",
       "       'Stop_Count', 'RawTokens', 'Title_Count', 'Upper_Count', 'PRON_Count',\n",
       "       'DET_Count', 'ADV_Count', 'VERB_Count', 'PROPN_Count', 'NOUN_Count',\n",
       "       'NUM_Count', 'PUNCT_Count', 'SYM_Count', 'SCONJ_Count', 'CCONJ_Count',\n",
       "       'INTJ_Count', 'AUX_Count', 'ADP_Count', 'ADJ_Count', 'PRON_Ratio',\n",
       "       'DET_Ratio', 'ADV_Ratio', 'VERB_Ratio', 'PROPN_Ratio', 'NOUN_Ratio',\n",
       "       'NUM_Ratio', 'PUNCT_Ratio', 'SYM_Ratio', 'SCONJ_Ratio', 'CCONJ_Ratio',\n",
       "       'INTJ_Ratio', 'AUX_Ratio', 'ADP_Ratio', 'ADJ_Ratio', 'TTR', 'HTR',\n",
       "       'BoW_PCA_1', 'BoW_PCA_2', 'BoW_PCA_3', 'TFIDF_PCA_1', 'TFIDF_PCA_2',\n",
       "       'TFIDF_PCA_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>TAS20</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Card</th>\n",
       "      <th>T_Metaphors</th>\n",
       "      <th>T_ToM</th>\n",
       "      <th>...</th>\n",
       "      <th>ADP_Ratio</th>\n",
       "      <th>ADJ_Ratio</th>\n",
       "      <th>TTR</th>\n",
       "      <th>HTR</th>\n",
       "      <th>BoW_PCA_1</th>\n",
       "      <th>BoW_PCA_2</th>\n",
       "      <th>BoW_PCA_3</th>\n",
       "      <th>TFIDF_PCA_1</th>\n",
       "      <th>TFIDF_PCA_2</th>\n",
       "      <th>TFIDF_PCA_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.429786</td>\n",
       "      <td>-0.056197</td>\n",
       "      <td>-0.360772</td>\n",
       "      <td>-0.114870</td>\n",
       "      <td>0.168706</td>\n",
       "      <td>0.031455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.535592</td>\n",
       "      <td>0.971355</td>\n",
       "      <td>-0.133005</td>\n",
       "      <td>0.867802</td>\n",
       "      <td>0.301337</td>\n",
       "      <td>0.165452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.713317</td>\n",
       "      <td>-0.012597</td>\n",
       "      <td>-0.255988</td>\n",
       "      <td>-0.089725</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>0.031664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9VH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-0.280320</td>\n",
       "      <td>-0.445467</td>\n",
       "      <td>0.372081</td>\n",
       "      <td>-0.019208</td>\n",
       "      <td>-0.076310</td>\n",
       "      <td>-0.093545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.539096</td>\n",
       "      <td>0.998465</td>\n",
       "      <td>-0.135003</td>\n",
       "      <td>0.393093</td>\n",
       "      <td>0.108074</td>\n",
       "      <td>0.043623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Code  TAS20  F1  F2  F3  Gender  Age  Card  \\\n",
       "0  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22     1   \n",
       "1  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22  13HM   \n",
       "2  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22     1   \n",
       "3  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22   9VH   \n",
       "4  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22  13HM   \n",
       "\n",
       "   T_Metaphors  T_ToM  ...  ADP_Ratio  ADJ_Ratio       TTR       HTR  \\\n",
       "0            0      1  ...   0.125000   0.000000  0.562500  0.875000   \n",
       "1            0      1  ...   0.000000   0.000000  0.857143  1.000000   \n",
       "2            0      1  ...   0.103448   0.172414  0.344828  0.793103   \n",
       "3            0      1  ...   0.208333   0.083333  0.458333  0.875000   \n",
       "4            0      1  ...   0.100000   0.200000  0.900000  1.000000   \n",
       "\n",
       "  BoW_PCA_1  BoW_PCA_2  BoW_PCA_3  TFIDF_PCA_1  TFIDF_PCA_2 TFIDF_PCA_3  \n",
       "0  0.429786  -0.056197  -0.360772    -0.114870     0.168706    0.031455  \n",
       "1 -0.535592   0.971355  -0.133005     0.867802     0.301337    0.165452  \n",
       "2  0.713317  -0.012597  -0.255988    -0.089725     0.143005    0.031664  \n",
       "3 -0.280320  -0.445467   0.372081    -0.019208    -0.076310   -0.093545  \n",
       "4 -0.539096   0.998465  -0.135003     0.393093     0.108074    0.043623  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpora\n",
    "Let's get two corpora, one with \"alexithymic language\" and the other with \"non-alexithymic language\". \n",
    "- AlexDoc will contain merged text from TAS-20 positive users. \n",
    "- NoAlexDoc will contain merged text from TAS-20 negative users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the alexithymic lang together\n",
    "AlexDoc = ' '.join(alex_df[alex_df.Alex_A == 1].Text)\n",
    "\n",
    "# Get all non-alexithymic lang together\n",
    "NoAlexDoc = ' '.join(alex_df[alex_df.Alex_A == 0].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, we have a quite unbalanced dataset: Alex: 10285; NoAlex: 63589.\n"
     ]
    }
   ],
   "source": [
    "print(\"As expected, we have a quite unbalanced dataset: Alex: %d; NoAlex: %d.\" % (len(AlexDoc),len(NoAlexDoc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All to lower case and remove punctuation\n",
    "AlexDoc = AlexDoc.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "NoAlexDoc = NoAlexDoc.translate(str.maketrans('', '', string.punctuation)).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating N-Gram models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the length of the n-grams\n",
    "char_ngram_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Char n-gram calculation function. \n",
    "def compute_char_ngrams(doc, length):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        Document to extract n-grams from. \n",
    "    length : int\n",
    "        Length of the n-grams (2 is bigram, 3 is a trigram, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    char_ngrams = {}\n",
    "    \n",
    "    for i in range(len(doc)-length):  # For each char i in doc\n",
    "        seq = doc[i:i+length]         # Get current sequence\n",
    "        # print(seq)\n",
    "        if seq not in char_ngrams.keys():       # Create entry for new sequences\n",
    "            char_ngrams[seq] = []                  \n",
    "        char_ngrams[seq].append(doc[i+length])  # Add new char\n",
    "    \n",
    "    return char_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute char n-grams for the two corpora\n",
    "alex_char_ngrams = compute_char_ngrams(AlexDoc, char_ngram_length)\n",
    "noalex_char_ngrams = compute_char_ngrams(NoAlexDoc, char_ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u', 'u', 'u', 'u']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_char_ngrams.get(\"niño q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'd', 'd', 'd', 'd']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noalex_char_ngrams.get(\"lloran\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the char n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "charNGramAlex_path = \"D:\\\\Dropbox-Array2001\\\\Dropbox\\\\DataSets\\\\Prolexitim-Dataset\\\\Prolexitim_v2_CharNGram_Alex.json\"\n",
    "charNGramNoAlex_path = \"D:\\\\Dropbox-Array2001\\\\Dropbox\\\\DataSets\\\\Prolexitim-Dataset\\\\Prolexitim_v2_CharNGram_NoAlex.json\"\n",
    "\n",
    "with open(charNGramAlex_path, 'w', encoding='utf8') as fp:\n",
    "    json.dump(alex_char_ngrams, fp, ensure_ascii=False)\n",
    "    \n",
    "with open(charNGramNoAlex_path, 'w', encoding='utf8') as fp:\n",
    "    json.dump(noalex_char_ngrams, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting text with the Char N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Gram based char generation function. \n",
    "def predict_chars(seed, ng_model, ng_length, gen_length):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : str\n",
    "        Initial sequence of chars to generate from. \n",
    "    ng_model : dict\n",
    "        Dictionary with the char N-Gram model. \n",
    "    ng_length : int\n",
    "        Length of the n-grams (2 is bigram, 3 is a trigram, etc.)\n",
    "    gen_length : int\n",
    "        Length of the string to be generated.        \n",
    "    \"\"\"\n",
    "    if (len(seed) != ng_length):\n",
    "        raise Exception(\"Seed length shoud be equal to N-Grams length.\")\n",
    "    \n",
    "    generated = seed  # We start with the seed. \n",
    "\n",
    "    for i in range(gen_length):\n",
    "        if seed not in ng_model.keys():\n",
    "            break\n",
    "        possible_chars = ng_model[seed]\n",
    "        next_char = possible_chars[random.randrange(len(possible_chars))]\n",
    "        generated += next_char\n",
    "        seed = generated[len(generated)-ng_length:len(generated)] # New seed is now the last sequence.   \n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carlitos él tiene que todos juntos y animales nunca habían pasado la noche de pasion con sus amigos y sienten muchas ideas geniales en medio de trabajo una siesta la faena que cercanía y se durmiendo a este'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speak in \"alexithymic language\" prediction \n",
    "predict_chars(\"carlit\", alex_char_ngrams, char_ngram_length, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'carlitos con mucho más adecuada para siempre ha terminado un hombre pobre que ahora si quedaba cierta paz y la señores que eso le apetecía nada tocar el violín y tirar flechas con mucha más cercanos el agua'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speak in \"non-alexithymic language\" prediction \n",
    "predict_chars(\"carlit\", noalex_char_ngrams, char_ngram_length, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niño que tiene un gesto un hombre le regalo su abuelitos'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speak in \"non-alexithymic language\" prediction \n",
    "predict_chars(\"niño q\", noalex_char_ngrams, char_ngram_length, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the length of the n-grams\n",
    "# Let's go for word trigrams\n",
    "word_ngram_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word n-gram calculation function. \n",
    "def compute_word_ngrams(doc, length):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        Document to extract n-grams from. \n",
    "    length : int\n",
    "        Length of the n-grams (2 is bigram, 3 is a trigram, etc.)\n",
    "    \"\"\"\n",
    "    ngrams = {}\n",
    "    \n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    for i in range(len(tokens)-length):\n",
    "        seq = ' '.join(tokens[i:i+length])\n",
    "        # print(seq)\n",
    "        if seq not in ngrams.keys():\n",
    "            ngrams[seq] = []\n",
    "        ngrams[seq].append(tokens[i+length])\n",
    "        \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute word n-grams for the two corpora\n",
    "alex_word_ngrams = compute_word_ngrams(AlexDoc, word_ngram_length)\n",
    "noalex_word_ngrams = compute_word_ngrams(NoAlexDoc, word_ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arar']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_word_ngrams.get('largo día de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trabajo', 'trabajo']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noalex_word_ngrams.get('largo día de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the word n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNGramAlex_path = \"D:\\\\Dropbox-Array2001\\\\Dropbox\\\\DataSets\\\\Prolexitim-Dataset\\\\Prolexitim_v2_WordNGram_Alex.json\"\n",
    "wordNGramNoAlex_path = \"D:\\\\Dropbox-Array2001\\\\Dropbox\\\\DataSets\\\\Prolexitim-Dataset\\\\Prolexitim_v2_WordNGram_NoAlex.json\"\n",
    "\n",
    "with open(wordNGramAlex_path, 'w', encoding='utf8') as fp:\n",
    "    json.dump(alex_word_ngrams, fp, ensure_ascii=False)\n",
    "    \n",
    "with open(wordNGramNoAlex_path, 'w', encoding='utf8') as fp:\n",
    "    json.dump(noalex_word_ngrams, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting text with the Word N-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-Gram based word generation function. \n",
    "def predict_words(seed, ng_model, ng_length, gen_length):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : str\n",
    "        Initial sequence of words to generate from. \n",
    "    ng_model : dict\n",
    "        Dictionary with the word N-Gram model. \n",
    "    ng_length : int\n",
    "        Length of the n-grams (2 is bigram, 3 is a trigram, etc.)\n",
    "    gen_length : int\n",
    "        Length of the string to be generated (in words).        \n",
    "    \"\"\"\n",
    "    seed_words = nltk.word_tokenize(seed)\n",
    "    \n",
    "    if (len(seed_words) != ng_length):\n",
    "        raise Exception(\"Seed length shoud be equal to N-Grams length.\")\n",
    "    \n",
    "    generated = seed\n",
    "    for i in range(gen_length):\n",
    "        if seed not in ng_model.keys():\n",
    "            break\n",
    "        possible_words = ng_model[seed]\n",
    "        next_word = possible_words[random.randrange(len(possible_words))]\n",
    "        generated += ' ' + next_word\n",
    "        seq_words = nltk.word_tokenize(generated)\n",
    "        seed = ' '.join(seq_words[len(seq_words)-ng_length:len(seq_words)])\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'largo día de arar la tierra un dia una persona estaba caminando por un bosque cercano a su hogar y ha llegado a un lugar maravilloso donde la mano del hombre nunca había llegado la naturaleza se habia encargado de poner todo en su sitio así todos todos los elementos interactúaban y cooperaban'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate alexithymic text\n",
    "predict_words('largo día de', alex_word_ngrams, word_ngram_length, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'largo día de trabajo llegó la plácida siesta mereció la pena aguantar un poco más y saborear ese delicioso cochinillo que con tanto cariño le había reglado su abuelo se ponía una gran presión sobre sus hombros más de la que su propio abuelo pretendía con aquel presente ¿cómo si quiera podría iniciarse'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate non-alexithymic text\n",
    "predict_words('largo día de', noalex_word_ngrams, word_ngram_length, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un niño que deseaba con todas sus fuerzas tocar el violín pero sus padres le obligaban a estudiar una carrera con más salidas un grupo de exploradores que iban a hacer un recorrido por una gran montaña pero se les hizo de noche y tuvieron que acampar todos juntos encima del césped una cascada en mitad de la naturaleza donde todos los animales cuando se acercaba el buen tiempo se dirigían para estar horas y horas tocando el violin estaba deseoso de poder salir a jugar un grupo de trabajadores que tras la jornada de trabajo se reencontraban con sus sueños los que'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_words('un niño que', noalex_word_ngrams, word_ngram_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un niño que le gustaba descubrir cosas y decidió subir por unas escaleras que descubrió cuando sus padres fueron a un bar se adentró en un mundo mágico en el que lo pasamos muy bien esta era la historía de un señor anciano en el que habitaban los animales mas extraños que os podríais imaginar pero todos ellos tenían una característica común todos ellos estaban privados del sentido de la vista porque no tenían ojos esta particularidad les había llevado a desarrollar sus otros sentidos lo que a priori nos podría parecer un handicap tenía también algunas ventajas como por ejemplo que como'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_words('un niño que', noalex_word_ngrams, word_ngram_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un niño que quería tocar una guitarra pero le regalaron un violín estaba tumbado con sus amigos viajando en un tren destino a lo desconocido en su viaje en elefante tenía que cruzar una gran catarata fue lento y tortuoso pero al final lo consiguió la acababa de conocer en una discoteca y habían pasado la noche juntos y ahí estaba ella muerta por un ataque al corazón y el sin saber que hacer… un niño al que no le gustaba la música pero sus padres le obligaban a tocar el violin un padre y sus hijos deecansando un dia de fiesta en'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_words('un niño que', alex_word_ngrams, word_ngram_length, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
