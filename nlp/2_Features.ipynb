{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Analysis of Alexithymic Discourse\n",
    "\n",
    "<hr>\n",
    "\n",
    "Alexithymic Language Project / raul@psicobotica.com / V2 release (sept 2020)\n",
    "\n",
    "<hr>\n",
    "\n",
    "### NLP Feature Engineering\n",
    "\n",
    "- Pre-processed Dataset load (already tokenized, stemmed, POS, NER, Lex, Dep parsed). \n",
    "- Cuantitative variables: counts (chars, words, sentences, punctuation, stopwords, title words, etc.)\n",
    "- Cuantitative variables: average lengths.\n",
    "- Cuantitative variables: POS frequencies.\n",
    "- Cuantitative variables: diversity scores (HTR, TTR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processed Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset_path = \"https://raw.githubusercontent.com/raul-arrabales/alexithymic-lang/master/data/Prolexitim_v2_processed_dep.csv\"\n",
    "\n",
    "alex_df = pd.read_csv(processed_dataset_path, header=0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Code.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Code', 'TAS20', 'F1', 'F2', 'F3', 'Gender', 'Age', 'Card',\n",
       "       'T_Metaphors', 'T_ToM', 'T_FP', 'T_Interpret', 'T_Desc', 'T_Confussion',\n",
       "       'Text', 'Alex_A', 'Alex_B', 'Words', 'Sentences', 'Tokens',\n",
       "       'Tokens_Stop', 'Tokens_Stem_P', 'Tokens_Stem_S', 'POS', 'NER', 'DEP',\n",
       "       'Lemmas_CNLP', 'Lemmas_Spacy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>TAS20</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Card</th>\n",
       "      <th>T_Metaphors</th>\n",
       "      <th>T_ToM</th>\n",
       "      <th>...</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens_Stop</th>\n",
       "      <th>Tokens_Stem_P</th>\n",
       "      <th>Tokens_Stem_S</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "      <th>DEP</th>\n",
       "      <th>Lemmas_CNLP</th>\n",
       "      <th>Lemmas_Spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['es', 'un', 'niño', 'pensando', 'en', 'cual',...</td>\n",
       "      <td>['niño', 'pensando', 'respuesta', 'deberes', '...</td>\n",
       "      <td>['niño', 'pensando', 'respuesta', 'deber', 'sa...</td>\n",
       "      <td>['niñ', 'pens', 'respuest', 'deber', 'sab']</td>\n",
       "      <td>[('es', 'AUX'), ('un', 'DET'), ('niño', 'NOUN'...</td>\n",
       "      <td>[('es', 'O'), ('un', 'O'), ('niño', 'O'), ('pe...</td>\n",
       "      <td>[[(('niño', 'NOUN'), 'cop', ('es', 'AUX')), ((...</td>\n",
       "      <td>es un niño pensando en cual es la respuesta de...</td>\n",
       "      <td>['es', 'un', 'niño', 'pensar', 'en', 'cual', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['hombre', 'llorando', 'porque', 'su', 'mujer'...</td>\n",
       "      <td>['hombre', 'llorando', 'mujer', 'muerto']</td>\n",
       "      <td>['hombr', 'llorando', 'mujer', 'muerto']</td>\n",
       "      <td>['hombr', 'llor', 'muj', 'muert']</td>\n",
       "      <td>[('hombre', 'NOUN'), ('llorando', 'VERB'), ('p...</td>\n",
       "      <td>[('hombre', 'O'), ('llorando', 'O'), ('porque'...</td>\n",
       "      <td>[[(('llorando', 'VERB'), 'nsubj', ('hombre', '...</td>\n",
       "      <td>hombre llorando porque su mujer ha muerto .</td>\n",
       "      <td>['hombre', 'llorando', 'porque', 'su', 'mujer'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>['un', 'niño', 'cansado', 'de', 'estudiar', 'y...</td>\n",
       "      <td>['niño', 'cansado', 'estudiar', 'presionado', ...</td>\n",
       "      <td>['niño', 'cansado', 'estudiar', 'presionado', ...</td>\n",
       "      <td>['niñ', 'cans', 'estudi', 'presion', 'padr', '...</td>\n",
       "      <td>[('un', 'DET'), ('niño', 'NOUN'), ('cansado', ...</td>\n",
       "      <td>[('un', 'O'), ('niño', 'O'), ('cansado', 'O'),...</td>\n",
       "      <td>[[(('niño', 'NOUN'), 'det', ('un', 'DET')), ((...</td>\n",
       "      <td>un niño cansado de estudiar y presionado por s...</td>\n",
       "      <td>['un', 'niño', 'cansado', 'de', 'estudiar', 'y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9VH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>['grupo', 'de', 'amigos', 'después', 'de', 'un...</td>\n",
       "      <td>['grupo', 'amigos', 'después', 'noche', 'diver...</td>\n",
       "      <td>['grupo', 'amigo', 'despué', 'noch', 'diversió...</td>\n",
       "      <td>['grup', 'amig', 'despues', 'noch', 'diversion...</td>\n",
       "      <td>[('grupo', 'NOUN'), ('de', 'ADP'), ('amigos', ...</td>\n",
       "      <td>[('grupo', 'O'), ('de', 'O'), ('amigos', 'O'),...</td>\n",
       "      <td>[[(('grupo', 'NOUN'), 'nmod', ('amigos', 'NOUN...</td>\n",
       "      <td>grupo de amigos después de una noche de divers...</td>\n",
       "      <td>['grupo', 'de', 'amigo', 'después', 'de', 'un'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['hombre', 'desolado', 'porque', 'se', 'ha', '...</td>\n",
       "      <td>['hombre', 'desolado', 'encontrado', 'mujer', ...</td>\n",
       "      <td>['hombr', 'desolado', 'encontrado', 'mujer', '...</td>\n",
       "      <td>['hombr', 'desol', 'encontr', 'muj', 'fallec']</td>\n",
       "      <td>[('hombre', 'NOUN'), ('desolado', 'ADJ'), ('po...</td>\n",
       "      <td>[('hombre', 'O'), ('desolado', 'O'), ('porque'...</td>\n",
       "      <td>[[(('hombre', 'NOUN'), 'amod', ('desolado', 'A...</td>\n",
       "      <td>hombre desolado porque se ha encontrado a su m...</td>\n",
       "      <td>['hombre', 'desolado', 'porque', 'se', 'ha', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Code  TAS20  F1  F2  F3  Gender  Age  Card  \\\n",
       "0  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22     1   \n",
       "1  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22  13HM   \n",
       "2  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22     1   \n",
       "3  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22   9VH   \n",
       "4  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22  13HM   \n",
       "\n",
       "   T_Metaphors  T_ToM  ...  Sentences  \\\n",
       "0            0      1  ...          2   \n",
       "1            0      1  ...          2   \n",
       "2            0      1  ...          4   \n",
       "3            0      1  ...          3   \n",
       "4            0      1  ...          2   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  ['es', 'un', 'niño', 'pensando', 'en', 'cual',...   \n",
       "1  ['hombre', 'llorando', 'porque', 'su', 'mujer'...   \n",
       "2  ['un', 'niño', 'cansado', 'de', 'estudiar', 'y...   \n",
       "3  ['grupo', 'de', 'amigos', 'después', 'de', 'un...   \n",
       "4  ['hombre', 'desolado', 'porque', 'se', 'ha', '...   \n",
       "\n",
       "                                         Tokens_Stop  \\\n",
       "0  ['niño', 'pensando', 'respuesta', 'deberes', '...   \n",
       "1          ['hombre', 'llorando', 'mujer', 'muerto']   \n",
       "2  ['niño', 'cansado', 'estudiar', 'presionado', ...   \n",
       "3  ['grupo', 'amigos', 'después', 'noche', 'diver...   \n",
       "4  ['hombre', 'desolado', 'encontrado', 'mujer', ...   \n",
       "\n",
       "                                       Tokens_Stem_P  \\\n",
       "0  ['niño', 'pensando', 'respuesta', 'deber', 'sa...   \n",
       "1           ['hombr', 'llorando', 'mujer', 'muerto']   \n",
       "2  ['niño', 'cansado', 'estudiar', 'presionado', ...   \n",
       "3  ['grupo', 'amigo', 'despué', 'noch', 'diversió...   \n",
       "4  ['hombr', 'desolado', 'encontrado', 'mujer', '...   \n",
       "\n",
       "                                       Tokens_Stem_S  \\\n",
       "0        ['niñ', 'pens', 'respuest', 'deber', 'sab']   \n",
       "1                  ['hombr', 'llor', 'muj', 'muert']   \n",
       "2  ['niñ', 'cans', 'estudi', 'presion', 'padr', '...   \n",
       "3  ['grup', 'amig', 'despues', 'noch', 'diversion...   \n",
       "4     ['hombr', 'desol', 'encontr', 'muj', 'fallec']   \n",
       "\n",
       "                                                 POS  \\\n",
       "0  [('es', 'AUX'), ('un', 'DET'), ('niño', 'NOUN'...   \n",
       "1  [('hombre', 'NOUN'), ('llorando', 'VERB'), ('p...   \n",
       "2  [('un', 'DET'), ('niño', 'NOUN'), ('cansado', ...   \n",
       "3  [('grupo', 'NOUN'), ('de', 'ADP'), ('amigos', ...   \n",
       "4  [('hombre', 'NOUN'), ('desolado', 'ADJ'), ('po...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  [('es', 'O'), ('un', 'O'), ('niño', 'O'), ('pe...   \n",
       "1  [('hombre', 'O'), ('llorando', 'O'), ('porque'...   \n",
       "2  [('un', 'O'), ('niño', 'O'), ('cansado', 'O'),...   \n",
       "3  [('grupo', 'O'), ('de', 'O'), ('amigos', 'O'),...   \n",
       "4  [('hombre', 'O'), ('desolado', 'O'), ('porque'...   \n",
       "\n",
       "                                                 DEP  \\\n",
       "0  [[(('niño', 'NOUN'), 'cop', ('es', 'AUX')), ((...   \n",
       "1  [[(('llorando', 'VERB'), 'nsubj', ('hombre', '...   \n",
       "2  [[(('niño', 'NOUN'), 'det', ('un', 'DET')), ((...   \n",
       "3  [[(('grupo', 'NOUN'), 'nmod', ('amigos', 'NOUN...   \n",
       "4  [[(('hombre', 'NOUN'), 'amod', ('desolado', 'A...   \n",
       "\n",
       "                                         Lemmas_CNLP  \\\n",
       "0  es un niño pensando en cual es la respuesta de...   \n",
       "1        hombre llorando porque su mujer ha muerto .   \n",
       "2  un niño cansado de estudiar y presionado por s...   \n",
       "3  grupo de amigos después de una noche de divers...   \n",
       "4  hombre desolado porque se ha encontrado a su m...   \n",
       "\n",
       "                                        Lemmas_Spacy  \n",
       "0  ['es', 'un', 'niño', 'pensar', 'en', 'cual', '...  \n",
       "1  ['hombre', 'llorando', 'porque', 'su', 'mujer'...  \n",
       "2  ['un', 'niño', 'cansado', 'de', 'estudiar', 'y...  \n",
       "3  ['grupo', 'de', 'amigo', 'después', 'de', 'un'...  \n",
       "4  ['hombre', 'desolado', 'porque', 'se', 'ha', '...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuantitative NLP features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char count (Chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['Chars'] = alex_df.Text.apply(lambda x: sum(len(word) for word in str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean     158.706037\n",
       "std      118.689279\n",
       "min       22.000000\n",
       "25%       78.000000\n",
       "50%      123.000000\n",
       "75%      203.000000\n",
       "max      744.000000\n",
       "Name: Chars, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Chars.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word length (avgWL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['avgWL'] = alex_df.Chars / alex_df.Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       4.555929\n",
       "std        0.482036\n",
       "min        3.388889\n",
       "25%        4.225806\n",
       "50%        4.545455\n",
       "75%        4.831169\n",
       "max        6.000000\n",
       "Name: avgWL, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.avgWL.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sentence length (avgSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['avgSL'] = alex_df.Words / alex_df.Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean      11.390465\n",
       "std        5.762169\n",
       "min        2.500000\n",
       "25%        7.333333\n",
       "50%       10.500000\n",
       "75%       14.500000\n",
       "max       51.333333\n",
       "Name: avgSL, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.avgSL.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puctuation Count (Pun_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = lambda l1, l2: len(list(filter(lambda c: c in l2, l1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['Pun_Count'] = alex_df.Text.apply(lambda text: count(text,set(string.punctuation))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       3.761155\n",
       "std        3.523330\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%        5.000000\n",
       "max       31.000000\n",
       "Name: Pun_Count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Pun_Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words Count (Stop_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk stop words for Spanish doesn't seem sufficient\n",
    "# ! pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words in Spanish \n",
    "es_stop = list(stopwords.words('spanish'))\n",
    "es_stop2 = list(get_stop_words('spanish'))\n",
    "es_stop.extend(es_stop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([w for w in ['hola','que','haces','perro',';','dia','sdfs','es'] if w in es_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['Stop_Count'] = alex_df.Tokens.apply(lambda tokens: len([w for w in ast.literal_eval(tokens) if w in es_stop])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean      18.325459\n",
       "std       13.690723\n",
       "min        1.000000\n",
       "25%        9.000000\n",
       "50%       15.000000\n",
       "75%       24.000000\n",
       "max       82.000000\n",
       "Name: Stop_Count, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Stop_Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Words Count (Title_Count)\n",
    "A title word is defined as any word starting with a capital letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'd need to add the list of tokens without lower()\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "alex_df['RawTokens'] = alex_df.apply(lambda row: tokenizer.tokenize(row.Text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['Title_Count'] = alex_df.RawTokens.apply(lambda tokens: len([w for w in tokens if w[0].isupper()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       1.645669\n",
       "std        1.708466\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        2.000000\n",
       "max       13.000000\n",
       "Name: Title_Count, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Title_Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Case char count (Upper_Count)\n",
    "Number of chars capitalized wihtin the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_df['Upper_Count'] = alex_df.Text.apply(lambda text: sum(1 for c in text if c.isupper())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       1.658793\n",
       "std        1.724165\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        2.000000\n",
       "max       13.000000\n",
       "Name: Upper_Count, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_df.Upper_Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoS Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of POS tags\n",
    "VERB_Count<br>\n",
    "NOUN_Count<br>\n",
    "SYM_Count<br>\n",
    "ADV_Count\t<br>\n",
    "PUNCT_Count<br>\n",
    "INTJ_Count<br>\n",
    "CCONJ_Count<br>\n",
    "ADJ_Count<br>\n",
    "AUX_Count<br>\n",
    "DET_Count<br>\n",
    "SCONJ_Count<br>\n",
    "PRON_Count<br>\n",
    "NUM_Count<br>\n",
    "PROPN_Count<br>\n",
    "ADP_Count<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of possible POS tags \n",
    "POS_tags = set()\n",
    "\n",
    "for str_posList in alex_df.POS:\n",
    "    posList = ast.literal_eval(str_posList)\n",
    "    for posPair in posList:\n",
    "        POS_tags.add(posPair[1])\n",
    "# POS_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON_Count</th>\n",
       "      <th>DET_Count</th>\n",
       "      <th>ADV_Count</th>\n",
       "      <th>VERB_Count</th>\n",
       "      <th>PROPN_Count</th>\n",
       "      <th>NOUN_Count</th>\n",
       "      <th>NUM_Count</th>\n",
       "      <th>PUNCT_Count</th>\n",
       "      <th>SYM_Count</th>\n",
       "      <th>SCONJ_Count</th>\n",
       "      <th>CCONJ_Count</th>\n",
       "      <th>INTJ_Count</th>\n",
       "      <th>AUX_Count</th>\n",
       "      <th>ADP_Count</th>\n",
       "      <th>ADJ_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PRON_Count, DET_Count, ADV_Count, VERB_Count, PROPN_Count, NOUN_Count, NUM_Count, PUNCT_Count, SYM_Count, SCONJ_Count, CCONJ_Count, INTJ_Count, AUX_Count, ADP_Count, ADJ_Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df with POS tag counts\n",
    "cNames = [] # Count column name\n",
    "tNames = [] # Original tag name\n",
    "\n",
    "for tag in POS_tags:\n",
    "    cNames.append(tag+'_Count')\n",
    "    tNames.append(tag)\n",
    "    \n",
    "POS_Counts_df = df = pd.DataFrame(columns = cNames)\n",
    "POS_Counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each exemplar, for each POS tag list, for each tag: count\n",
    "\n",
    "for str_posList in alex_df.POS:\n",
    "    posList = ast.literal_eval(str_posList)\n",
    "    counts = []\n",
    "    for tag in tNames:\n",
    "        tagCount = 0        \n",
    "        for posPair in posList:\n",
    "            if posPair[1] == tag:\n",
    "                tagCount += 1\n",
    "        counts.append(tagCount)\n",
    "    row = pd.Series(counts, index=POS_Counts_df.columns)\n",
    "    POS_Counts_df = POS_Counts_df.append(row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON_Count</th>\n",
       "      <th>DET_Count</th>\n",
       "      <th>ADV_Count</th>\n",
       "      <th>VERB_Count</th>\n",
       "      <th>PROPN_Count</th>\n",
       "      <th>NOUN_Count</th>\n",
       "      <th>NUM_Count</th>\n",
       "      <th>PUNCT_Count</th>\n",
       "      <th>SYM_Count</th>\n",
       "      <th>SCONJ_Count</th>\n",
       "      <th>CCONJ_Count</th>\n",
       "      <th>INTJ_Count</th>\n",
       "      <th>AUX_Count</th>\n",
       "      <th>ADP_Count</th>\n",
       "      <th>ADJ_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRON_Count DET_Count ADV_Count VERB_Count PROPN_Count NOUN_Count NUM_Count  \\\n",
       "0          2         3         1          2           0          3         0   \n",
       "1          0         1         0          2           0          2         0   \n",
       "2          5         3         0          5           0          2         0   \n",
       "3          3         2         1          1           0          5         0   \n",
       "4          1         1         0          1           0          2         0   \n",
       "\n",
       "  PUNCT_Count SYM_Count SCONJ_Count CCONJ_Count INTJ_Count AUX_Count  \\\n",
       "0           1         0           1           0          0         2   \n",
       "1           1         0           1           0          0         1   \n",
       "2           3         0           3           2          0         1   \n",
       "3           2         0           1           1          0         3   \n",
       "4           1         0           1           0          0         1   \n",
       "\n",
       "  ADP_Count ADJ_Count  \n",
       "0         2         0  \n",
       "1         0         0  \n",
       "2         3         5  \n",
       "3         5         2  \n",
       "4         1         2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_Counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat to the main df (append new columns)\n",
    "POS_Counts_df = POS_Counts_df.reset_index(drop=True)\n",
    "alex_df = alex_df.reset_index(drop=True)\n",
    "\n",
    "feats_df = pd.concat([alex_df,POS_Counts_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Code', 'TAS20', 'F1', 'F2', 'F3', 'Gender', 'Age', 'Card',\n",
       "       'T_Metaphors', 'T_ToM', 'T_FP', 'T_Interpret', 'T_Desc', 'T_Confussion',\n",
       "       'Text', 'Alex_A', 'Alex_B', 'Words', 'Sentences', 'Tokens',\n",
       "       'Tokens_Stop', 'Tokens_Stem_P', 'Tokens_Stem_S', 'POS', 'NER', 'DEP',\n",
       "       'Lemmas_CNLP', 'Lemmas_Spacy', 'Chars', 'avgWL', 'avgSL', 'Pun_Count',\n",
       "       'Stop_Count', 'RawTokens', 'Title_Count', 'Upper_Count', 'PRON_Count',\n",
       "       'DET_Count', 'ADV_Count', 'VERB_Count', 'PROPN_Count', 'NOUN_Count',\n",
       "       'NUM_Count', 'PUNCT_Count', 'SYM_Count', 'SCONJ_Count', 'CCONJ_Count',\n",
       "       'INTJ_Count', 'AUX_Count', 'ADP_Count', 'ADJ_Count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Relative frequency of POS \n",
    "Proportion of each POS relative to the total number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in tNames:\n",
    "    feats_df[tag+'_Ratio'] = feats_df.apply(lambda row: row[tag+'_Count'] / row['Words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>TAS20</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Card</th>\n",
       "      <th>T_Metaphors</th>\n",
       "      <th>T_ToM</th>\n",
       "      <th>...</th>\n",
       "      <th>NOUN_Ratio</th>\n",
       "      <th>NUM_Ratio</th>\n",
       "      <th>PUNCT_Ratio</th>\n",
       "      <th>SYM_Ratio</th>\n",
       "      <th>SCONJ_Ratio</th>\n",
       "      <th>CCONJ_Ratio</th>\n",
       "      <th>INTJ_Ratio</th>\n",
       "      <th>AUX_Ratio</th>\n",
       "      <th>ADP_Ratio</th>\n",
       "      <th>ADJ_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9VH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Code  TAS20  F1  F2  F3  Gender  Age  Card  \\\n",
       "0  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22     1   \n",
       "1  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22  13HM   \n",
       "2  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22     1   \n",
       "3  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22   9VH   \n",
       "4  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22  13HM   \n",
       "\n",
       "   T_Metaphors  T_ToM  ...  NOUN_Ratio  NUM_Ratio  PUNCT_Ratio  SYM_Ratio  \\\n",
       "0            0      1  ...    0.187500        0.0     0.062500        0.0   \n",
       "1            0      1  ...    0.285714        0.0     0.142857        0.0   \n",
       "2            0      1  ...    0.068966        0.0     0.103448        0.0   \n",
       "3            0      1  ...    0.208333        0.0     0.083333        0.0   \n",
       "4            0      1  ...    0.200000        0.0     0.100000        0.0   \n",
       "\n",
       "  SCONJ_Ratio  CCONJ_Ratio  INTJ_Ratio  AUX_Ratio  ADP_Ratio ADJ_Ratio  \n",
       "0    0.062500     0.000000         0.0   0.125000   0.125000  0.000000  \n",
       "1    0.142857     0.000000         0.0   0.142857   0.000000  0.000000  \n",
       "2    0.103448     0.068966         0.0   0.034483   0.103448  0.172414  \n",
       "3    0.041667     0.041667         0.0   0.125000   0.208333  0.083333  \n",
       "4    0.100000     0.000000         0.0   0.100000   0.100000  0.200000  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Diversity Scores\n",
    "https://en.wikipedia.org/wiki/Lexical_diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Token Ratio (TTR)\n",
    "Calculates the overall complexity of the text based on the total number of unique word types used in the text.<br>\n",
    "The total number of unique words divided by the total number of words in order to give the text a score from 0 to 1.<br>\n",
    "This is a very text length sensible score. Not really significant for comparison if texts are not of the same length. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOfTypes( row ):\n",
    "    num = 0\n",
    "    for typeToken in cNames: \n",
    "        if row[typeToken] > 0: \n",
    "            num += 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df['TTR'] = feats_df.apply( lambda row: numberOfTypes(row) / len(ast.literal_eval(row.Tokens)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       0.377069\n",
       "std        0.193790\n",
       "min        0.071429\n",
       "25%        0.229167\n",
       "50%        0.344828\n",
       "75%        0.478261\n",
       "max        1.000000\n",
       "Name: TTR, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.TTR.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapax legomena/Token ratio (HTR)\n",
    "The number of words that occur only once divided by the number of total words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df['HTR'] = feats_df.apply(\n",
    "    lambda row: len(set(ast.literal_eval(row.Tokens))) / len(ast.literal_eval(row.Tokens)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    381.000000\n",
       "mean       0.855941\n",
       "std        0.102061\n",
       "min        0.512000\n",
       "25%        0.787234\n",
       "50%        0.864865\n",
       "75%        0.933333\n",
       "max        1.000000\n",
       "Name: HTR, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.HTR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Code', 'TAS20', 'F1', 'F2', 'F3', 'Gender', 'Age', 'Card',\n",
       "       'T_Metaphors', 'T_ToM', 'T_FP', 'T_Interpret', 'T_Desc', 'T_Confussion',\n",
       "       'Text', 'Alex_A', 'Alex_B', 'Words', 'Sentences', 'Tokens',\n",
       "       'Tokens_Stop', 'Tokens_Stem_P', 'Tokens_Stem_S', 'POS', 'NER', 'DEP',\n",
       "       'Lemmas_CNLP', 'Lemmas_Spacy', 'Chars', 'avgWL', 'avgSL', 'Pun_Count',\n",
       "       'Stop_Count', 'RawTokens', 'Title_Count', 'Upper_Count', 'PRON_Count',\n",
       "       'DET_Count', 'ADV_Count', 'VERB_Count', 'PROPN_Count', 'NOUN_Count',\n",
       "       'NUM_Count', 'PUNCT_Count', 'SYM_Count', 'SCONJ_Count', 'CCONJ_Count',\n",
       "       'INTJ_Count', 'AUX_Count', 'ADP_Count', 'ADJ_Count', 'PRON_Ratio',\n",
       "       'DET_Ratio', 'ADV_Ratio', 'VERB_Ratio', 'PROPN_Ratio', 'NOUN_Ratio',\n",
       "       'NUM_Ratio', 'PUNCT_Ratio', 'SYM_Ratio', 'SCONJ_Ratio', 'CCONJ_Ratio',\n",
       "       'INTJ_Ratio', 'AUX_Ratio', 'ADP_Ratio', 'ADJ_Ratio', 'TTR', 'HTR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>TAS20</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Card</th>\n",
       "      <th>T_Metaphors</th>\n",
       "      <th>T_ToM</th>\n",
       "      <th>...</th>\n",
       "      <th>PUNCT_Ratio</th>\n",
       "      <th>SYM_Ratio</th>\n",
       "      <th>SCONJ_Ratio</th>\n",
       "      <th>CCONJ_Ratio</th>\n",
       "      <th>INTJ_Ratio</th>\n",
       "      <th>AUX_Ratio</th>\n",
       "      <th>ADP_Ratio</th>\n",
       "      <th>ADJ_Ratio</th>\n",
       "      <th>TTR</th>\n",
       "      <th>HTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc39e22ca5dba59fbd97c27987878f56</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>9VH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20cd825cadb95a71763bad06e142c148</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>13HM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Code  TAS20  F1  F2  F3  Gender  Age  Card  \\\n",
       "0  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22     1   \n",
       "1  bc39e22ca5dba59fbd97c27987878f56     40  16   9  15       2   22  13HM   \n",
       "2  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22     1   \n",
       "3  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22   9VH   \n",
       "4  20cd825cadb95a71763bad06e142c148     40  12  10  18       2   22  13HM   \n",
       "\n",
       "   T_Metaphors  T_ToM  ...  PUNCT_Ratio  SYM_Ratio  SCONJ_Ratio  CCONJ_Ratio  \\\n",
       "0            0      1  ...     0.062500        0.0     0.062500     0.000000   \n",
       "1            0      1  ...     0.142857        0.0     0.142857     0.000000   \n",
       "2            0      1  ...     0.103448        0.0     0.103448     0.068966   \n",
       "3            0      1  ...     0.083333        0.0     0.041667     0.041667   \n",
       "4            0      1  ...     0.100000        0.0     0.100000     0.000000   \n",
       "\n",
       "  INTJ_Ratio  AUX_Ratio  ADP_Ratio  ADJ_Ratio       TTR       HTR  \n",
       "0        0.0   0.125000   0.125000   0.000000  0.562500  0.875000  \n",
       "1        0.0   0.142857   0.000000   0.000000  0.857143  1.000000  \n",
       "2        0.0   0.034483   0.103448   0.172414  0.344828  0.793103  \n",
       "3        0.0   0.125000   0.208333   0.083333  0.458333  0.875000  \n",
       "4        0.0   0.100000   0.100000   0.200000  0.900000  1.000000  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dataset_path = \"D:\\\\Dropbox-Array2001\\\\Dropbox\\\\DataSets\\\\Prolexitim-Dataset\\\\Prolexitim_v2_features.csv\"\n",
    "feats_df.to_csv(features_dataset_path, sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
